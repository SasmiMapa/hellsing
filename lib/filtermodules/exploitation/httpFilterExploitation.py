import re

class httpFilterExploitation:
    def __init__(self):
        self.results = []
        
    #------------------------------------------------------------------------------------
    
    # filter hydra output
    def parse_hydra_output(self, output):
        """
        Parses the output of the Hydra tool to extract the cracked password.
        """
        pattern = r"\[\d+\]\[http-post-form\] host: ([^\s]+)\s+login: ([^\s]+)\s+password: ([^\s]+)"
        match = re.search(pattern, output)
        
        if match:
            return {
                "Host": match.group(1),
                "Login": match.group(2),
                "Password": match.group(3)
                }
        else:
            return None
        
    #------------------------------------------------------------------------------------
    
    def parse_sqlmap_db_scan_output(self, output):
        """
        Parses the output of the SQLMap tool to extract the database scan results.
        """
        databases_section = re.search(r"available databases \[\d+\]:\n(\[\*\] .+\n)+", output)
        
        if databases_section:
            # If the databases section is found, extract only the database names
            pattern = r"\[\*\] (.+)"
            return re.findall(pattern, databases_section.group(0))
        else:
            return []
        
    #------------------------------------------------------------------------------------
    
    def parse_sqlmap_table_dump_output(self, output):
        """
        Parses the output of the SQLMap tool to extract the table dump results.
        """
        tables = re.findall(r'\|\s+(\w+)\s+\|', output)
        
        if tables:
            return tables
        
        
    #------------------------------------------------------------------------------------
    
    def parse_sqlmap_column_dump_output(self, output):
        """
        Parses the output of the SQLMap tool to extract the column dump results.
        """
        database_name = None
        table_name = None
        columns = []
        values = []
        in_data_section = False
        found_column_names = False

        for line in output.split("\n"):
            # Extract database name
            if "Database:" in line:
                database_name = line.split(":")[1].strip()
            # Extract table name
            elif "Table:" in line:
                table_name = line.split(":")[1].strip()
            # Detect the start of the data section
            elif line.startswith("[1 entry]") or ("entry]" in line and line.startswith("[")) or ("entries]" in line and line.startswith("[")):
                in_data_section = True
            # Detect the end of the data section
            elif line.startswith("[INFO]") or line.startswith("[*] ending"):
                in_data_section = False
                found_column_names = False  # Reset for the next table, if any
            # Extract column names, avoiding lines that are just part of the table grid
            elif in_data_section and "|" in line and not found_column_names:
                columns = [col.strip() for col in line.split("|")[1:-1]]
                found_column_names = True
            # Extract data rows, ensuring they are part of the data section and columns are already found
            elif in_data_section and found_column_names and "|" in line:
                row_values = [val.strip() for val in line.split("|")[1:-1]]
                values.append(dict(zip(columns, row_values)))

        return {
            "database_name": database_name,
            "table_name": table_name,
            "columns": columns,
            "values": values
        }
            
            
        
        